{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mtcnn\n",
    "import pandas as pd\n",
    "from numpy import asarray\n",
    "from PIL import Image\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from os import listdir\n",
    "from os.path import isdir\n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the face in the image\n",
    "def extract_human_face(filename, size_needed=(160,160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert image to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "\n",
    "    x1, y1 =  abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "\n",
    "    # extract the face using the coordinates\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "\n",
    "    # resize pizels to the model size\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(size_needed) # or  Image.resize((160,160))  # naturally, I prefer 224 x 224 but oh well\n",
    "    face_array = asarray(image)\n",
    "    \n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/Users/Kenechi/Artifical Intelligence/Project Vindler/FaceRecognition-Vindler/face_data/whoisthis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = pd.read_csv('/Users/Kenechi/Artifical Intelligence/Project Vindler/FaceRecognition-Vindler/face_data/name_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tagging the tags to the names\n",
    "def names(name_file):\n",
    "    name_tag= dict()\n",
    "    for i in range(len(name_file)):\n",
    "        name, tags = name_file[\"image_name\"][i], name_file['tags'][i]\n",
    "        name_tag[name] = tags\n",
    "    return(name_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see = names(name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset\n",
    "\n",
    "def create_dataset(directory, name_file):\n",
    "    \n",
    "    name_targ = names(name_file)\n",
    "    x, y = list(), list()\n",
    "    faces = list()\n",
    "    targets = []\n",
    "    \n",
    "    for sub in listdir(directory):\n",
    "        if sub != 'Thumbs.db':\n",
    "            print(sub)\n",
    "            path = directory + sub #+ '/'\n",
    "            \n",
    "            print(path)\n",
    "\n",
    "            # load faces\n",
    "            face = extract_human_face(path)\n",
    "            \n",
    "            faces.append(face)\n",
    "\n",
    "            # load targets\n",
    "            targets.append(name_targ[sub.split('.')[0]])\n",
    "\n",
    "            x.extend(faces)\n",
    "            y.extend(targets)\n",
    "\n",
    "    return asarray(x), asarray(y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the data for x and y\n",
    "train_data_x, train_data_y = create_dataset(folder, name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_x.shape)\n",
    "print(train_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data_x[:11000]\n",
    "train_y = train_data_y[:11000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = train_data_x[11000:]\n",
    "test_y = train_data_y[11000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Train shape for the features {train_x.shape}')\n",
    "print(f'Train shape for the Targets {train_y.shape}')\n",
    "print(f'Test shape for the features {test_x.shape}')\n",
    "print(f'Test shape for the Targets {test_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.imshow(test_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining the facenet model\n",
    "embedder = FaceNet()\n",
    "\n",
    "# load the pre-trained facenet model\n",
    "model = load_model('facenet_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the embeddings\n",
    "def get_embedding(face_pixels):\n",
    "    # scale pixel values\n",
    "    print('Creating Embeddings ... ')\n",
    "    face_pixels = face_pixels.astype('float32')\n",
    "    print(f'face images after float32{face_pixels.shape}')\n",
    "    # standardize pixel values across channels (global)\n",
    "    mean,std =face_pixels.mean(), face_pixels.std()\n",
    "    face_pixels = (face_pixels - mean) / std\n",
    "    \n",
    "    # transform face into one sample\n",
    "    samples = expand_dims(face_pixels, axis=0)\n",
    "    print(f'samples after expand_dims{samples.shape}')\n",
    "    \n",
    "    \n",
    "    # make prediction to get embedding\n",
    "    #embedding = embedder.embeddings(samples)\n",
    "    #print(f'embeddings {embedding.shape}')\n",
    "    \n",
    "    y_embed = model.predict(samples)\n",
    "    # get embedding\n",
    "    embedding = y_embed[0]\n",
    "    \n",
    "    print(embedding)\n",
    "    \n",
    "    \n",
    "    print(' ')\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_train_x = []\n",
    "embedded_test_x = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the embeddings for training \n",
    "for face_pixels in train_x:\n",
    "    embedding = get_embedding(face_pixels)\n",
    "    embedded_train_x.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the embeddings for testing\n",
    "for face_pixels in test_x:\n",
    "    embedding = get_embedding(face_pixels)\n",
    "    embedded_test_x.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(embedded_train_x) == len(train_y)\n",
    "assert len(embedded_test_x) == len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to array\n",
    "embedded_train_x =  asarray(embedded_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the data\n",
    "embedded_train_x = embedded_train_x.reshape((11000, 1*128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "norm = Normalizer(norm='l2') # using the ridge regularizer\n",
    "embedded_train_x = norm.transform(embedded_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(embedded_train_x) == len(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to array\n",
    "embedded_test_x =  asarray(embedded_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the data\n",
    "embedded_test_x = embedded_test_x.reshape((325, 1*128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "embedded_test_x= norm.transform(embedded_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(embedded_test_x) == len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train,y_test = train_test_split(embedded_train_x, train_y , test_size = 0.2, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the svm model\n",
    "Facemodel = SVC(kernel='linear', probability=True)\n",
    "Facemodel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = Facemodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_pred, y_test) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see how it performs on embedded x test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train,y_test = train_test_split(embedded_test_x, test_y , test_size = 0.1, random_state = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = Facemodel.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = confusion_matrix(y_train, y_pred1)\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_pred1, y_train) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = Facemodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = confusion_matrix(y_test, y_pred2)\n",
    "print(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_pred2, y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking random Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  pick a random image\n",
    "def check_random_image(x, n):\n",
    "    face = x[random.randint(0, n)] \n",
    "    sample = expand_dims(face, axis=0)\n",
    "\n",
    "    #face_embedding = embedder.embeddings(sample)\n",
    "    face_embedding =  model.predict(sample)\n",
    "    face_embedding = face_embedding[0]\n",
    "    face_embedding = face_embedding.reshape((1, 1*128))\n",
    "    y_predict = Facemodel.predict(face_embedding)\n",
    "    y_prob2 = Facemodel.predict_proba(face_embedding)\n",
    "    pyplot.imshow(face)\n",
    "    title = '%s (%.3f)' % (y_predict[0], y_prob2[0][0] * 100)\n",
    "    pyplot.title(title)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_random_image(test_x, len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion:\n",
    "# WE NEED MORE DATA, 30 PER FACE IS NOT ENOUGH FOR THE FACENET MODEL BUT IS PERFECTLY FINE FOR THE PRE-TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT REFERENCES:\n",
    "\n",
    "# https://ai.stackexchange.com/questions/4864/what-is-the-concept-of-tensorflow-bottlenecks#:~:text=In%20a%20CNN%20(such%20as,output%20channels%20than%20input%20channels.\n",
    "# https://stats.stackexchange.com/questions/262044/what-does-a-bottleneck-layer-mean-in-neural-networks\n",
    "# https://machinelearningmastery.com/introduction-to-1x1-convolutions-to-reduce-the-complexity-of-convolutional-neural-networks/\n",
    "# https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/\n",
    "# https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
    "# http://faculty.juniata.edu/rhodes/ml/simdissim.htm\n",
    "# https://medium.com/analytics-vidhya/triplet-loss-b9da35be21b8\n",
    "# https://mathworld.wolfram.com/Hypersphere.html\n",
    "# https://stats.stackexchange.com/questions/63558/difference-between-standard-and-spherical-k-means-algorithms/63650#:~:text=In%20each%20step%2C%20k%2Dmeans,distance%20measure%20is%20cosine%20dissimilarity.\n",
    "# https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31\n",
    "# https://medium.com/konvergen/an-introduction-to-adagrad-f130ae871827\n",
    "# https://towardsdatascience.com/breaking-down-the-agglomerative-clustering-process-1c367f74c7c2\n",
    "\n",
    "# CODE REFERENCES:\n",
    "\n",
    "# https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/\n",
    "# https://medium.com/clique-org/how-to-create-a-face-recognition-model-using-facenet-keras-fd65c0b092f1\n",
    "# https://sefiks.com/2018/09/03/face-recognition-with-facenet-in-keras/\n",
    "# https://pypi.org/project/keras-facenet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
