{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os import listdir, mkdir\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import asarray\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating User Data for Registeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facecascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates a directory\n",
    "def create_directory(directory_name, path_to_directory):\n",
    "    # Path \n",
    "    path = os.path.join(path_to_directory, directory_name) \n",
    "    \n",
    "    mkdir(path) \n",
    "    return(print('Done!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Name \n",
    "directory = \"imagebucket\"\n",
    "\n",
    "# Parent Directory path \n",
    "parent_dir = \"/Users/Kenechi/Artifical Intelligence/Project Vindler/FaceRecognition-Vindler/\"\n",
    "\n",
    "# Create the directory\n",
    "create_directory(directory , parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create user faceimage data\n",
    "def generate_dataset(image, p_id, image_id):\n",
    "    cv2.imwrite(f'{directory}/user.'+str(p_id)+'.'+str(image_id)+'.jpg',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to draw boundry around face in image\n",
    "def draw_boundary(image, classifier, scalefactor, min_neighbors, color, text):\n",
    "    gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features = classifier.detectMultiScale(gray_scale, scalefactor, min_neighbors)\n",
    "    coordinates = []\n",
    "    \n",
    "    for (x, y, w, h) in features:\n",
    "        cv2.rectangle(image, (x,y),(x+w, y+h), color, 1)        \n",
    "        cv2.putText(image, text, (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv2.LINE_AA)\n",
    "        coordinates = [x, y, w, h]\n",
    "        \n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to obtain face boundry in image\n",
    "\n",
    "def detect(image, facecascade, image_id, p_id ):\n",
    "    color = {'blue':(0,0,255), 'red':(255,0,0), 'green':(0,255,0), 'white':(255,255,255)}\n",
    "    coordinate = draw_boundary(image, facecascade, 1.1, 10, color['white'], 'Detecting Face')\n",
    "    \n",
    "    if len(coordinate)== 4:\n",
    "        area_of_focus = image[coordinate[1]:coordinate[1]+coordinate[3], coordinate[0]:coordinate[0]+coordinate[2]]\n",
    "               \n",
    "        #p_id = 1\n",
    "        generate_dataset(area_of_focus, p_id, image_id)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data(p_id):\n",
    "    \n",
    "    print('PLEASE LOOK INTO THE SCREEN TILL IT DISAPPEARS.')\n",
    "   \n",
    "    video_capture  = cv2.VideoCapture(0) #if using an external webcam type in -1 inplace of 0\n",
    "    image_id = 0\n",
    "\n",
    "    while True:\n",
    "        _ ,image = video_capture.read()\n",
    "        image = detect(image, facecascade, image_id, p_id)\n",
    "        cv2.imshow('Collecting Face Images for Registration', image)\n",
    "        image_id += 1\n",
    "        if image_id == 300:#cv2.waitKey(1) & 0xFF == ord('e'): # to break loop press e\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return(print('Thank You!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_id=int(input('Type in your ID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_data(p_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that creates features and targets\n",
    "def load_train_images(directory):\n",
    "    train_pictures = list()\n",
    "    targets = list()\n",
    "    \n",
    "    print('Converting to numpy array ...')\n",
    "    for picture in listdir(directory) :\n",
    "         if picture != 'Thumbs.db':\n",
    "                 # load the picture from directory\n",
    "                photo = load_img(directory + picture, target_size = (224,224))\n",
    "                \n",
    "                #convert image to numpy array\n",
    "                photo = img_to_array(photo, dtype='uint8')  \n",
    "                \n",
    "                # append to list\n",
    "                train_pictures.append(photo)\n",
    "                \n",
    "                \n",
    "                # label targets\n",
    "                targets.append(picture.split('.')[1])\n",
    "                \n",
    "                \n",
    "    print(' ')\n",
    "    \n",
    "    X = asarray(train_pictures, dtype = 'uint8')\n",
    "    Y = asarray(targets, dtype = 'uint8')\n",
    "    \n",
    "    X_r = np.array(X).reshape((300, 224*224))\n",
    "    \n",
    "    pca_t = PCA()\n",
    "    pca_t.fit(X_r)\n",
    "    \n",
    "    explained_variance = pca_t.explained_variance_ratio\n",
    "    cumsum = np.cumsum(explained_variance)\n",
    "    n_comp = np.argmax(cumsum1 >= 0.99) + 1 \n",
    "    \n",
    "    pca_m= PCA(n_components = n_comp)\n",
    "    x = pca_m.fit(X_r)\n",
    "    \n",
    "    Fclassifier = SVC(class_weight='balanced',C= 1, kernel= 'linear')\n",
    "    \n",
    "    Fclassifier.partial_fit(x_train, y_train) # HERE IS THE PARTIAL FIT SHENANIGAN!\n",
    "    \n",
    "\n",
    "    \n",
    "    print(' ')\n",
    "    print('Done!')\n",
    "    return Fclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fclassifier = load_train_images(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boundary(image, classifier, scalefactor, min_neighbors, color, text, Fclassifier):\n",
    "    gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features = classifier.detectMultiScale(gray_scale, scalefactor, min_neighbors)\n",
    "    coordinates = []\n",
    "    \n",
    "    for (x, y, w, h) in features:\n",
    "        cv2.rectangle(image, (x,y),(x+w, y+h), color, 1)\n",
    "        id_, _= Fclassifier.predict(gray_scale[y:y+h, x:x+w])\n",
    "        \n",
    "        if id_ == p_id:\n",
    "            cv2.putText(image, 'Hello User', (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv2.LINE_AA)\n",
    "            coordinates = [x, y, w, h]\n",
    "        \n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(image, Fclassifier,facecascade ):\n",
    "    color = {'blue':(0,0,255), 'red':(255,0,0), 'green':(0,255,0), 'white':(255,255,255)}\n",
    "    coordinate = draw_boundary(image,facecascade,1.1, 10, color['white'], 'FACE', Fclassifier)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(image):\n",
    "    height = 224\n",
    "    width = 224\n",
    "    dim = (width, height)\n",
    "    image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    return image\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grant_access():\n",
    "    auth_count = 0\n",
    "\n",
    "    while True:\n",
    "        _ ,image = video_capture.read()\n",
    "\n",
    "        image = resize(image)\n",
    "\n",
    "        #image = detect(image, facecascade, image_id)\n",
    "        image = recognize(image, Fclassifier, facecascade)\n",
    "        cv2.imshow('Approved', image)\n",
    "        auth_count += 1\n",
    "        if auth_count == 6:#cv2.waitKey(1) & 0xFF == ord('e'): # to break loop press e\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_access()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
